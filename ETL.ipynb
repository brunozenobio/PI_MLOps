{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import gzip\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEAM GAMES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primero cargo el dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steam_games = pd.read_json('./datasets/steam_games.json.gz',compression='gzip',lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steam_games.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steam_games.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elimino las filas completamente nulas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "steam_games.dropna(how='all',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Busco id nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "steam_games[steam_games['id'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se encontraron dos filas con id nulo, una solo posee valores de url y precio, ademas el url es de la store de steam por lo tanto se eliminara.\n",
    "### La otra fila con id nulo estaba replicada de otra fila, ya que tiene los mismos valores, por esto tambien se eliminara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steam_games[steam_games['title'] == 'Batman: Arkham City - Game of the Year Edition'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steam_games.dropna(subset=['id'],inplace=True) # Elimino las 2 filas con id nulo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Busco los duplicados en id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicados = steam_games['id'].value_counts() > 1\n",
    "steam_games[steam_games['id'].isin(duplicados[duplicados].index)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se encontraron dos filas completamente duplicadas se eliminara una"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steam_games.drop_duplicates(subset='id',inplace=True,keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convierto el id a tipo entero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steam_games['id'] = steam_games['id'].astype('int') # Paso el id a entero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steam_games.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steam_games[steam_games['app_name'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### El unico juego que posee nulo en app_name y title, no pose ni desarrolador ni publicador, por esto se eliminara."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# El unico juego que no tiene ni titulo ni app_name tampoco tiene desarrollador o publicador, solo pose genero tag y un url que lleva a ningun juego, por esto se eliminara esta fila\n",
    "steam_games.dropna(subset='app_name',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se remplazara los nulos de developer por los de publisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steam_games['developer'].fillna(steam_games['publisher'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se eliminaran las columnas que no seran usadas por el estudio.\n",
    "* publisher\n",
    "* title\n",
    "* url\n",
    "* discount_price\n",
    "* reviews_url\n",
    "* early_access\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steam_proc = steam_games.drop(columns=['publisher','title','url','reviews_url','early_access'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Veo que tags y genres son columnas con datos similares, por esto buscare los nulos en genres y en tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steam_proc[steam_proc['genres'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steam_proc[steam_proc['tags'].isna()]['genres']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ahora voy a eliminar los valores que no esten en alguna fila  de genres de la columna tag para tener solo los generos\n",
    "### Luego voy a agregar valores de tag que no esten en genres \n",
    "### Luego voy a remplazar los nulos de genres con los valores de tags\n",
    "### Por ultimo voy a eliminar la columna tags que ya no aporta informacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = set(item for val in steam_proc['genres'].dropna() for item in val)# Obtengo los valores unicos de genres\n",
    " \n",
    "steam_proc['tags'] = steam_proc['tags'].apply(lambda x: [item for item in x if item in genres] if isinstance(x, list) else x) # Los elimino de tags\n",
    "\n",
    "steam_proc['genres'].fillna(steam_proc['tags'],inplace=True) # Remplazo los nulos de genres con los valores de tags\n",
    "\n",
    "\n",
    "def agregar_genres_tags(fila): # Agrego valores de tangs en genres cuando estos no esten en genres.\n",
    "    genres = fila['genres']\n",
    "    tags = fila['tags']\n",
    "    if isinstance(tags,list) and isinstance(genres,list):\n",
    "        for tag in tags:\n",
    "            if tag not in genres:\n",
    "                genres.append(tag)\n",
    "    return genres\n",
    "steam_proc['genres'] = steam_proc.apply(lambda fila:agregar_genres_tags(fila),axis=1)\n",
    "\n",
    "\n",
    "steam_proc.drop(columns=['tags'],inplace=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genero dummies para la columna genres,  y luego eliminare esta ultima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ahora voy a generar dummies para genres \n",
    "steam_proc['genres'] =  steam_proc['genres'].apply(lambda x:\".\".join(x) if isinstance(x, list) else x)\n",
    "dummies = steam_proc['genres'].str.get_dummies(sep='.')\n",
    "#dummies = dummies.groupby(dummies.columns, axis=1).sum()\n",
    "steam_proc = pd.concat([steam_proc,dummies],axis=1)\n",
    "\n",
    "# Elimino la columna genres\n",
    "steam_proc.drop(columns='genres',inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columna Price:\n",
    "* Primero voy a poner en valor 0 los que tengan un str con Free"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "steam_proc.loc[steam_proc['price'].str.contains(\"Free\", na=False), 'price'] = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Reviso los valores de price y Free to Play\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steam_proc.loc[steam_proc['price'].apply(lambda x: isinstance(x, str)), ['price','Free to Play']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Remplazo los  valores que tenian un string y un precio por el precio asociado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A los dos valores que incluye el precio como parte de un string lo remplazo con su valor de precio\n",
    "steam_proc['price'].replace('Starting at $499.00',499.0,inplace=True)\n",
    "steam_proc['price'].replace('Starting at $449.00',499.0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Cuando precio posee un string y Free to Play vale 1 remplazo por 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "steam_proc.loc[(steam_proc['Free to Play'] == 1) & steam_proc['price'].apply(lambda x: isinstance(x, str)), ['price']] = 0.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Veo los valores nulos de price donde Free to Play vale 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steam_proc[pd.isna(steam_proc['price'])][['Free to Play']].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A esos valores los remplazo por 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steam_proc.loc[(steam_proc['Free to Play'] == 1) & (pd.isna(steam_proc['price'])), 'price'] = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Veo la cantidad de nulos que quedaron en price respecto al total,y veo que no llega al 4% de nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steam_proc[steam_proc['price'].isnull()].shape[0]/steam_proc.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Elimino el resto de nulos en price, al no poder realizarse mas un analisis , ya que no considero correcto remlplazar un precio por un premedio u otro valor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elimino los valores de precio donde sean nulos o donde o donde no sean de tipo string\n",
    "steam_proc = steam_proc[steam_proc['price'].apply(lambda x: isinstance(x, float))]\n",
    "steam_proc.dropna(subset='price',inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Tenindo normalizada esta columna la convierto a flaot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teniendo precio con formato numerico convierto la columna a float\n",
    "steam_proc['price'] = steam_proc['price'].astype('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Veo los nulos que aun quedaron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steam_proc.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Porcentaje de nulos : {steam_proc.dropna(subset=[\"developer\",\"release_date\",\"specs\"]).shape[0] / steam_proc.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quedaron valores nulos en release_date, developer y specs que equivalen aproximadamente al 11% del dataframe. \n",
    "### Y al no poder hacer otro tratado se eliminaran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voy a liminar el resto de valores nulos\n",
    "steam_proc.dropna(subset=['developer','release_date','specs'],inplace=True)\n",
    "steam_proc.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convierto la columna release_date en datetime y genero la columna año"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion de tipos\n",
    "steam_proc['release_date'] = pd.to_datetime(steam_proc['release_date'], errors='coerce')\n",
    "# Genero una columna para el año\n",
    "\n",
    "steam_proc['Year'] = steam_proc['release_date'].dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Por ultimo exporto como csv el proceso de ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steam_proc.to_csv('./datasets/steam_games.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USERS REVIEWS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ahora voy a trabajar con el archivo user_reviews.json.gz, el cual guarda registros de los comentarios de los usuarios sobre distintos items\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Primero realizo la carga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_reviews_gz = \"./datasets/user_reviews.json.gz\"\n",
    "filas=[]\n",
    "with gzip.open(user_reviews_gz, 'rt', encoding='MacRoman') as archivo:\n",
    "    for line in archivo.readlines():\n",
    "        filas.append(ast.literal_eval(line))\n",
    "\n",
    "user_review = pd.DataFrame(filas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ahora veo que la columna reviews es una lista de diccionarios, donde cada item de la lista equivale a un producto distinto que ese usuario haya comendado, y cada cada diccionario guarda variables referentes al item y su posteo.\n",
    "### Por esto primero voy a usar explode para duplicar las filas por cada item de la lista, y luego voy a generar un dataframe con el diccionario nuevo y lo concatenare a traves de las columnas con el el dataframe con filas duplicadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_review_explode = user_review.explode('reviews') # Duplico las filas generando un diccionario por cada dicc#ionario en la lista\n",
    "# Ahora concateno el dataframe original, con el dataframe generado a partir de transformar los diccionarios a pandas\n",
    "user_review_explode = pd.concat([user_review_explode.drop(['reviews'],axis=1),user_review_explode['reviews'].apply(pd.Series)],axis=1)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elimino columnas que no seran usadas para el estudio\n",
    "* user_url\n",
    "* funny\n",
    "* last_edited\n",
    "* helpful\n",
    "* 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_review_explode.drop(columns=['user_url','funny','helpful','last_edited',0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_review_explode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ahora a partir de la columna reveiw se hara un analisis de sentimiento, generando una nueva columna.\n",
    "### Este se llamara \"sentiment_analysis\"  y tendra 2 para sentimiento positivo 0 para negativo y 1 para neutral\n",
    "### Habiendo hecho esto elimino la columna review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hago el analisis de sentimiento en la columna review\n",
    "nltk.download('vader_lexicon')\n",
    "model_sentimiento = SentimentIntensityAnalyzer()\n",
    "\n",
    "\n",
    "def analizador(review):\n",
    "    # Obtener el puntaje de sentimiento usando SentimentIntensityAnalyzer\n",
    "    sentimiento_score = model_sentimiento.polarity_scores(review)\n",
    "    \n",
    "    # Clasifico el sentimiento\n",
    "    \n",
    "    if review and not pd.isnull(review):\n",
    "        if sentimiento_score['compound'] >= 0.05:\n",
    "            return 2  # Sentimiento positivo\n",
    "        elif sentimiento_score['compound'] <= -0.05:\n",
    "            return 0  # Sentimiento negativo\n",
    "        else:\n",
    "            return 1  # Sentimiento neutral\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Para aplicar la funcion los nulos tienen que ser vacio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_review_explode['review'].fillna('',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_review_explode['sentiment_analysis']  = user_review_explode['review'].apply(analizador)\n",
    "user_review_explode.drop(columns='review',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Grafico las el analisis por sentimiento de las reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=user_review_explode,x='sentiment_analysis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se buscan los nulos que quedaron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_review_explode.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_review_explode[user_review_explode.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hay nulos pero coiciden con todas las columnas de reviews por esto se eliminaran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "user_review_explode.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_review_explode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Por ultimo se exporta como csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_review_explode.to_csv('./datasets/user_reviews.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Users Item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_df(ruta, variable_anidada):\n",
    "    '''Función que recibe una ruta de acceso a un archivo json anidado y carga la información en un\n",
    "    DataFrame de Pandas'''\n",
    "    fila = []\n",
    "    with gzip.open(ruta, 'rt', encoding='MacRoman') as archivo:\n",
    "      for line in archivo.readlines():\n",
    "          fila.append(ast.literal_eval(line))\n",
    "\n",
    "    df = pd.DataFrame(fila)                                                 \n",
    "    df = df.explode(variable_anidada).reset_index()                         \n",
    "    df = df.drop(columns=\"index\")                                           \n",
    "    df = pd.concat([df, pd.json_normalize(df[variable_anidada])], axis=1)   \n",
    "    df = df.drop(columns=variable_anidada)                                  \n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_items = cargar_df(\"./datasets/users_items.json.gz\",'items')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_items.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.boxplot(data=user_items,y='playtime_forever')\n",
    "sns.boxplot(data=user_items,y='items_count')\n",
    "plt.ylabel(0,2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_items.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_items[user_items['item_id'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Todos los nulos hacen referencia a las mismas filas por esto seran eliminados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_items.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_items.to_csv('./datasets/users_item_proc.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('user_items_proc.csv.gz', 'wb') as f:\n",
    "    user_items.to_csv(f, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fila = []\n",
    "with gzip.open('./datasets/users_items.json.gz', 'rt', encoding='MacRoman') as archivo:\n",
    "      for line in archivo.readlines():\n",
    "          fila.append(ast.literal_eval(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_items_explode = pd.DataFrame(fila).explode('items')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('user_items.csv.gz', 'wb') as f:\n",
    "    user_items_explode.to_csv(f, index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "steam-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
