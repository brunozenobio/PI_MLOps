{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo de recomendacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargo el dataset usado para el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise.model_selection import train_test_split as train_test_splitSV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from surprise import SVD\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise import accuracy\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_reviews = pd.read_csv('../datasets/user_reviews.csv',usecols=['user_id','item_id','sentiment_analysis','recommend'])\n",
    "label_encoder = LabelEncoder()\n",
    "#elimino la columna user_id\n",
    "user_reviews['user_id_num'] = label_encoder.fit_transform(user_reviews['user_id'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voy a generar un rating a partir de recommend y sentiment_analysis para que este entre 0 y 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_reviews['rating'] = np.where(user_reviews['recommend'] == True,  # Si 'recommend' es True\n",
    "                                 np.where(user_reviews['sentiment_analysis'] == 2, 5,  # Si 'sentimiento' es positivo\n",
    "                                          np.where(user_reviews['sentiment_analysis'] == 1, 3,  # Si 'sentimiento' es neutro\n",
    "                                                   1)),  # Si 'sentimiento' es negativo cuando 'recommend' es True\n",
    "                                 np.where(user_reviews['sentiment_analysis'] == 2, 4,  # Si 'sentimiento' es positivo\n",
    "                                          np.where(user_reviews['sentiment_analysis'] == 1, 2,  # Si 'sentimiento' es neutro\n",
    "                                                   0)))  # Si 'sentimiento' es negativo cuando 'recommend' es False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>recommend</th>\n",
       "      <th>sentiment_analysis</th>\n",
       "      <th>user_id_num</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50605</th>\n",
       "      <td>76561198063055125</td>\n",
       "      <td>239070</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>5348</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53520</th>\n",
       "      <td>76561198076114293</td>\n",
       "      <td>17460</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>7647</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46727</th>\n",
       "      <td>newhollandarmy</td>\n",
       "      <td>223470</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>22668</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46078</th>\n",
       "      <td>76561198024028497</td>\n",
       "      <td>227100</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1647</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53714</th>\n",
       "      <td>TheMarshmallowMan101</td>\n",
       "      <td>730</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>17361</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    user_id  item_id  recommend  sentiment_analysis  \\\n",
       "50605     76561198063055125   239070       True                   2   \n",
       "53520     76561198076114293    17460       True                   2   \n",
       "46727        newhollandarmy   223470       True                   1   \n",
       "46078     76561198024028497   227100      False                   0   \n",
       "53714  TheMarshmallowMan101      730       True                   2   \n",
       "\n",
       "       user_id_num  rating  \n",
       "50605         5348       5  \n",
       "53520         7647       5  \n",
       "46727        22668       3  \n",
       "46078         1647       0  \n",
       "53714        17361       5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "user_reviews.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(user_reviews['rating'].max())\n",
    "print(user_reviews['rating'].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genero id numericos para user_id usando label encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(0,5))\n",
    "data = Dataset.load_from_df(user_reviews[['user_id_num','item_id','rating']], reader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separo el dataset en entrenamiento y testeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test = train_test_splitSV(data,test_size = .25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voy a usar un modelo De descomposicion en valor singular (SVD), el cual es un filtro colaborativo\n",
    "### Voy a usar los datos de \n",
    "* user_id\n",
    "* item_id\n",
    "* sentiment_analysis: como rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplico GridSearch para encontrar al modelo con los mejores hiperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_factors': [5,50,100],'n_epochs': [5, 10,20], 'lr_all': [0.001, 0.002, 0.005],\n",
    "              'reg_all': [0.002, 0.02, 0.2]}\n",
    "\n",
    "gs = GridSearchCV(SVD, param_grid, measures=['rmse'], cv=3, n_jobs = -1)\n",
    "gs.fit(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5840100111706839\n",
      "{'n_factors': 100, 'n_epochs': 20, 'lr_all': 0.005, 'reg_all': 0.2}\n"
     ]
    }
   ],
   "source": [
    "print(gs.best_score['rmse'])\n",
    "print(gs.best_params['rmse'])\n",
    "best_model = gs.best_estimator['rmse']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Veo que el modelo tiene un rmse de 1.06 lo cual esta cerca de 1lo cual en la escala esta bien\n",
    "### Ademas veo los mejores hiperparametros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Por ultimo defino el modelo con los mejores hiperparametros y lo exporto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x7f3d9e6e1a30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = SVD(n_factors=100,n_epochs=20,lr_all=0.005,reg_all=0.2)\n",
    "model.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.2764\n",
      "RMSE en el conjunto de entrenamiento: 1.2764039278981176\n",
      "RMSE: 1.5817\n",
      "RMSE en el conjunto de prueba: 1.5817043122021668\n"
     ]
    }
   ],
   "source": [
    "from surprise import accuracy\n",
    "train_predictions = model.test(train.build_testset())\n",
    "test_predictions = model.test(test)\n",
    "print(f\"RMSE en el conjunto de entrenamiento: {accuracy.rmse(train_predictions)}\")\n",
    "print(f\"RMSE en el conjunto de prueba: {accuracy.rmse(test_predictions)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EL modelo obtuvo un mejor rendimiento en los datos de testeo el rmse 1.5 me indica que en en el ranking de 0 5 lo que indica una desviacion de 1.5 si bien tiene mucho rango de mejora para las columnas usadas como rating esta bastante bien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./SVD_model.pkl', 'wb') as file: # Exporto mi modelo\n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 4124       item: 12354      r_ui = None   est = 3.82   {'was_impossible': False}\n",
      "user: 4124       item: 1244       r_ui = None   est = 3.82   {'was_impossible': False}\n",
      "user: 4124       item: 154        r_ui = None   est = 3.82   {'was_impossible': False}\n",
      "user: 4124       item: 12554      r_ui = None   est = 3.82   {'was_impossible': False}\n",
      "user: 4124       item: 1213       r_ui = None   est = 3.82   {'was_impossible': False}\n",
      "user: 4124       item: 1884       r_ui = None   est = 3.82   {'was_impossible': False}\n",
      "user: 4124       item: 35354      r_ui = None   est = 3.82   {'was_impossible': False}\n",
      "user: 4124       item: 1324       r_ui = None   est = 3.82   {'was_impossible': False}\n",
      "user: 4124       item: 13224      r_ui = None   est = 3.82   {'was_impossible': False}\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(4124,12354))\n",
    "print(model.predict(4124,1244))\n",
    "print(model.predict(4124,154))\n",
    "print(model.predict(4124,12554))\n",
    "print(model.predict(4124,1213))\n",
    "print(model.predict(4124,1884))\n",
    "print(model.predict(4124,35354))\n",
    "print(model.predict(4124,1324))\n",
    "print(model.predict(4124,13224))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtro basado en contenido con Vecinos Cercanos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Este script trabaja con un dataset de juegos de Steam. Primero, cargamos el dataset utilizando pandas.\n",
    "steam_games = pd.read_csv('../datasets/steam_games.csv')\n",
    "\n",
    "# Luego identificamos y guardamos los nombres de las columnas del dataset que representan los géneros de los juegos.\n",
    "generos = list(steam_games.drop(columns=['app_name','price','id','developer','Accounting','Year']).columns)\n",
    "\n",
    "# Iniciamos una lista vacía para almacenar los perfiles de los items (juegos).\n",
    "perfiles_items = []\n",
    "\n",
    "# Iteramos sobre cada juego (fila) en el dataset y creamos una lista con los valores en cada una de las columnas de género.\n",
    "for _, row in steam_games.iterrows():\n",
    "    perfil_item = []\n",
    "    for genero in generos:\n",
    "        perfil_item.append(row[genero])\n",
    "    # Añadimos la lista del perfil del item a la lista principal de perfiles.\n",
    "    perfiles_items.append(perfil_item)\n",
    "\n",
    "# Convertimos la lista de perfiles de items en un DataFrame de pandas, utilizando los nombres de géneros como nombres de columnas.\n",
    "perfiles_items_df = pd.DataFrame(perfiles_items, columns=generos)\n",
    "\n",
    "# Añadimos las columnas 'app_name' e 'id' desde el dataset original al nuevo DataFrame.\n",
    "perfiles_items_df['app_name'] = steam_games['app_name']\n",
    "perfiles_items_df['id'] = steam_games['id']\n",
    "\n",
    "# Creamos un nuevo DataFrame que excluye la columna 'app_name', que servirá como nuestro modelo de datos.\n",
    "data_model = perfiles_items_df.drop(['app_name'], axis=1)\n",
    "\n",
    "# Utilizamos el StandardScaler para normalizar los valores en nuestro modelo de datos.\n",
    "scaler = StandardScaler()\n",
    "data_standar = scaler.fit_transform(data_model)\n",
    "\n",
    "# Guardamos nuestros perfiles de items normalizados como un nuevo archivo csv.\n",
    "perfiles_items_df.to_csv('../datasets/data_standar_nearest_model.csv',index=False)\n",
    "\n",
    "# Definimos el valor de k para nuestro modelo k-nearest neighbors.\n",
    "k = 5\n",
    "\n",
    "# Creamos e entrenamos nuestro modelo k-nearest neighbors utilizando la métrica euclideana.\n",
    "knn_model = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
    "knn_model.fit(data_standar)\n",
    "\n",
    "# Finalmente, guardamos nuestro modelo entrenado en un archivo .pkl para uso futuro.\n",
    "with open('./NearestNeighnors.pkl', 'wb') as file:\n",
    "    pickle.dump(knn_model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Recomendacion 1': \"Deus Ex: Human Revolution - Director's Cut\",\n",
       " 'Recomendacion 2': 'NARUTO SHIPPUDEN: Ultimate Ninja STORM 3 Full Burst HD',\n",
       " 'Recomendacion 3': 'System Shock 2',\n",
       " 'Recomendacion 4': 'Magicka 2'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def item_recommend_func(item_id):\n",
    "    # Cargar datos relevantes desde un archivo CSV.\n",
    "    perfiles_items_df = pd.read_csv('../datasets/data_standar_nearest_model.csv')\n",
    "    \n",
    "    if item_id not in list(perfiles_items_df['id']):\n",
    "        return {'Ese id no pertenece a un item registrado'}\n",
    "    else:\n",
    "        item_game = perfiles_items_df[perfiles_items_df['id'] == item_id]['app_name']\n",
    "\n",
    "    # Eliminar la columna 'app_name' de los datos.\n",
    "    data_model = perfiles_items_df.drop(['app_name'], axis=1)\n",
    "\n",
    "    # Inicializar y ajustar el escalador de características.\n",
    "    scaler = StandardScaler()\n",
    "    data_standar = scaler.fit_transform(data_model)\n",
    "\n",
    "    # Importamos modelo preentrenado de KNN\n",
    "    with open('./NearestNeighnors.pkl', 'rb') as file:  \n",
    "        knn_model = pickle.load(file)\n",
    "\n",
    "    # Obtener el índice del artículo basado en su nombre.\n",
    "    \n",
    "    item_index = perfiles_items_df[perfiles_items_df['app_name'] == item_name].index[0]\n",
    "\n",
    "    # Recuperar los vecinos más cercanos al artículo especificado.\n",
    "    distances, indices = knn_model.kneighbors([data_standar[item_index]])\n",
    "\n",
    "    # Crear un diccionario para almacenar las recomendaciones.\n",
    "    recomendaciones = {}\n",
    "    for i in range(1, len(indices[0])):  # Ignorar el primer vecino (ya que es el artículo mismo).\n",
    "        # Identificar el índice y el nombre del artículo recomendado.\n",
    "        recommended_item_index = indices[0][i]\n",
    "        recommended_item_name = perfiles_items_df.loc[recommended_item_index, 'app_name']\n",
    "        # Agregar recomendación al diccionario.\n",
    "        recomendaciones[f\"Recomendacion {i}\"] = recommended_item_name\n",
    "\n",
    "    # Devolver las recomendaciones como resultado.\n",
    "    return recomendaciones"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
